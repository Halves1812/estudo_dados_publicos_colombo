{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "624b9883-c0bd-46dd-a00a-9ab6cce4ff26",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GQ-_fqeGA9-x"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4b571696-4228-424d-b346-d06ce735bc5a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "rJJrKuxsA9-z"
      },
      "outputs": [],
      "source": [
        "# imports de bibliotecas\n",
        "from functools import reduce\n",
        "from pyspark.sql.functions import col, lit, when, concat, ceil\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9b9de239-f222-46cd-a799-18ce471318a2",
          "showTitle": true,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZXDOs3KgA9-2"
      },
      "source": [
        "# Métodos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cdb76e00-46d9-48cd-988f-fa20eac2f763",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MiffmBi1A9-2"
      },
      "source": [
        "Importação das origens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6960ed3-8b16-4987-a815-3df38e180e7e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "5XPnvKbwA9-2"
      },
      "outputs": [],
      "source": [
        "# cria tabelas de eleitorado a partir dos arquivos csv\n",
        "def cria_tabelas_eleitorado(anos_eleitorado):\n",
        "\tfor ano in anos_eleitorado:\n",
        "\t\tcsv_eleitorado = spark.read.csv(f\"/Volumes/workspace/perfil_eleitorado/tabelas_eleitorado/tb_eleitorado_{ano}.csv\", header=True, inferSchema=True)\n",
        "\t\tcsv_eleitorado.write.saveAsTable(f\"workspace.perfil_eleitorado.tb_eleitorado_{ano}\")\n",
        "\n",
        "# cria tabela de locais de votação a partir do arquivo csv\n",
        "def cria_tabela_locais_de_votacao():\n",
        "    csv_locais_de_votacao = spark.read.csv(\"/Volumes/workspace/perfil_eleitorado/tabelas_eleitorado/locais_de_votacao.csv\", header=True, inferSchema=True)\n",
        "    csv_locais_de_votacao.write.saveAsTable(\"workspace.perfil_eleitorado.locais_de_votacao\")\n",
        "\n",
        "# lê tabelas origem e salva em dataframes\n",
        "def ler_tabelas_origem():\n",
        "    tb_eleitorado_2024 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2024\")\n",
        "    tb_eleitorado_2022 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2022\")\n",
        "    tb_eleitorado_2020 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2020\")\n",
        "    tb_eleitorado_2018 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2018\")\n",
        "    tb_eleitorado_2016 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2016\")\n",
        "    tb_eleitorado_2014 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2014\")\n",
        "    tb_eleitorado_2012 = spark.table(\"workspace.perfil_eleitorado.tb_eleitorado_2012\")\n",
        "    locais_de_votacao = spark.table(\"workspace.perfil_eleitorado.locais_de_votacao\")\n",
        "    return (\n",
        "        tb_eleitorado_2024,\n",
        "        tb_eleitorado_2022,\n",
        "        tb_eleitorado_2020,\n",
        "        tb_eleitorado_2018,\n",
        "        tb_eleitorado_2016,\n",
        "        tb_eleitorado_2014,\n",
        "        tb_eleitorado_2012,\n",
        "        locais_de_votacao\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7671e666-755c-43ca-a11b-92ad3d84a186",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gHRhXN4lA9-3"
      },
      "source": [
        "Preparação das bases de origem (base de cálculo e base de validação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4b9ef297-85db-40af-a542-c7a9ea76643c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "R1Oy6SlXA9-3"
      },
      "outputs": [],
      "source": [
        "# une as tabelas utilizadas para base de cáculo\n",
        "def unificar_eleitorado(anos_eleitorado_modelo):\n",
        "\tdataframes = [globals()[f\"tb_eleitorado_{ano}\"] for ano in anos_eleitorado_modelo]\n",
        "\treturn reduce(lambda df1, df2: df1.unionByName(df2, allowMissingColumns=True), dataframes)\n",
        "\n",
        "# adiciona bairro aos dataframes de cálculo e validação\n",
        "def adicionar_bairro_eleitorado(df_eleitorado_unificado, locais_de_votacao):\n",
        "\tdf_eleitorado_bairro = df_eleitorado_unificado.join(\n",
        "\t\tlocais_de_votacao.select(\"ANO_ELEICAO\", \"ZONA\", \"NUMERO_LOCAL_VOTACAO\", \"BAIRRO\"),\n",
        "\t\ton=[\"ANO_ELEICAO\", \"ZONA\", \"NUMERO_LOCAL_VOTACAO\"],\n",
        "\t\thow=\"left\"\n",
        "\t)\n",
        "\treturn df_eleitorado_bairro\n",
        "\n",
        "# ajusta coluna de faixa etária\n",
        "def ajustar_faixa_etaria(df):\n",
        "    df = df.withColumn(\n",
        "        \"FAIXA_ETARIA\",\n",
        "        when(col(\"FAIXA_ETARIA\") == \"16 anos                       \", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"17 anos                       \", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"18 anos                       \", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"19 anos                       \", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"20 anos                       \", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"21 a 24 anos                  \", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"25 a 29 anos                  \", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"30 a 34 anos                  \", \"DE 30 A 39\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"35 a 39 anos                  \", \"DE 30 A 39\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"40 a 44 anos                  \", \"DE 40 A 49\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"45 a 49 anos                  \", \"DE 40 A 49\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"50 a 54 anos                  \", \"DE 50 A 59\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"55 a 59 anos                  \", \"DE 50 A 59\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"60 a 64 anos                  \", \"DE 60 A 69\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"65 a 69 anos                  \", \"DE 60 A 69\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"70 a 74 anos                  \", \"DE 70 A 79\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"75 a 79 anos                  \", \"DE 70 A 79\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"80 a 84 anos                  \", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"85 a 89 anos                  \", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"90 a 94 anos                  \", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"95 a 99 anos                  \", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"100 anos ou mais              \", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"16 anos\", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"17 anos\", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"18 anos\", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"19 anos\", \"MENOS QUE 20\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"20 anos\", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"21 a 24 anos\", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"25 a 29 anos\", \"DE 20 A 29\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"30 a 34 anos\", \"DE 30 A 39\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"35 a 39 anos\", \"DE 30 A 39\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"40 a 44 anos\", \"DE 40 A 49\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"45 a 49 anos\", \"DE 40 A 49\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"50 a 54 anos\", \"DE 50 A 59\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"55 a 59 anos\", \"DE 50 A 59\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"60 a 64 anos\", \"DE 60 A 69\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"65 a 69 anos\", \"DE 60 A 69\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"70 a 74 anos\", \"DE 70 A 79\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"75 a 79 anos\", \"DE 70 A 79\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"80 a 84 anos\", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"85 a 89 anos\", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"90 a 94 anos\", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"95 a 99 anos\", \"ACIMA DE 80\")\n",
        "        .when(col(\"FAIXA_ETARIA\") == \"100 anos ou mais\", \"ACIMA DE 80\")\n",
        "        .otherwise(col(\"FAIXA_ETARIA\"))\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# salva tabelas trabalhadas, completas\n",
        "def salvar_tabelas_trabalhadas(df_eleitorado_bairro, df_eleitorado_bairro_2024):\n",
        "    df_eleitorado_bairro.write.saveAsTable(\"workspace.perfil_eleitorado.eleitorado_bairro\")\n",
        "    df_eleitorado_bairro_2024.write.saveAsTable(\"workspace.perfil_eleitorado.eleitorado_bairro_2024\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "94f96248-013d-464c-af85-3255f728f23a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Dcnt6a5tA9-3"
      },
      "source": [
        "Preparação das bases agrupadas (base de cálculo e base de validação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "59c04272-e761-4061-ac94-64cb743db277",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "WT9sn1imA9-4"
      },
      "outputs": [],
      "source": [
        "# leitura das tabelas trabalhadas\n",
        "def ler_tabelas_trabalhadas():\n",
        "    df_eleitorado_bairro = spark.table(\"workspace.perfil_eleitorado.eleitorado_bairro\")\n",
        "    df_eleitorado_bairro_2024 = spark.table(\"workspace.perfil_eleitorado.eleitorado_bairro_2024\")\n",
        "    return df_eleitorado_bairro, df_eleitorado_bairro_2024\n",
        "\n",
        "# separação da amostra de trabalho\n",
        "def filtrar_bairro(df, bairro):\n",
        "    return df.filter(col(\"BAIRRO\") == bairro)\n",
        "\n",
        "# agrupamento pela quantidade total\n",
        "def agrupar_quantidade_total(df_base, tabela_destino):\n",
        "    df = (\n",
        "        df_base\n",
        "        .groupBy(col(\"ANO_ELEICAO\").alias(\"ano\"))\n",
        "        .agg({\"QUANTIDADE_ELEITORES\": \"sum\"})\n",
        "        .withColumnRenamed(\"sum(QUANTIDADE_ELEITORES)\", \"quantidade\")\n",
        "        .withColumn(\"agrupamento\", lit(\"QUANTIDADE TOTAL\"))\n",
        "        .orderBy(\"agrupamento\", \"ano\")\n",
        "        .select(\"ano\", \"agrupamento\", \"quantidade\")\n",
        "    )\n",
        "    df.write.saveAsTable(tabela_destino)\n",
        "\n",
        "# agrupamento pelas demais variáveis\n",
        "def agrupar_e_salvar(df_base, agrupamento_nome, agrupamento_coluna, tabela_destino):\n",
        "    df_qtd = (\n",
        "        df_base\n",
        "        .groupBy(\n",
        "            col(\"ANO_ELEICAO\").alias(\"ano\"),\n",
        "            col(agrupamento_coluna).alias(\"agrupamento\")\n",
        "        )\n",
        "        .agg({\"QUANTIDADE_ELEITORES\": \"sum\"})\n",
        "        .withColumnRenamed(\"sum(QUANTIDADE_ELEITORES)\", \"quantidade\")\n",
        "        .withColumn(\n",
        "            \"agrupamento\",\n",
        "            concat(lit(agrupamento_nome), col(\"agrupamento\"))\n",
        "        )\n",
        "        .orderBy(\"agrupamento\", \"ano\")\n",
        "    )\n",
        "    df_qtd.write.mode(\"append\").saveAsTable(tabela_destino)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8a00c00f-a8a0-4f7c-a240-2dab7be62ea0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GxxmiF7YA9-4"
      },
      "source": [
        "Projeção"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "61ccfff5-4f4b-461d-a199-4fbec4e9b7e4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GPvgmc3_A9-4"
      },
      "outputs": [],
      "source": [
        "# Projeta as informações a partir da base apontada\n",
        "def projetar_base(tabela_origem, tabela_destino):\n",
        "    base_predicao = spark.table(tabela_origem)\n",
        "    data = base_predicao.toPandas()\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for agrupamento in data['agrupamento'].unique():\n",
        "        df_agrupamento = data[data['agrupamento'] == agrupamento].sort_values('ano')\n",
        "        serie = df_agrupamento.set_index('ano')['quantidade']\n",
        "\n",
        "        # SES\n",
        "        ses = SimpleExpSmoothing(serie, initialization_method=\"estimated\").fit()\n",
        "        prev_ses = ses.forecast(1).iloc[0]\n",
        "\n",
        "        # ARIMA\n",
        "        arima = ARIMA(serie, order=(1, 1, 1)).fit()\n",
        "        prev_arima = arima.forecast(steps=1).iloc[0]\n",
        "\n",
        "        # SARIMA\n",
        "        sarima = SARIMAX(serie, order=(1, 1, 1), seasonal_order=(1, 0, 1, 2)).fit(disp=False)\n",
        "        prev_sarima = sarima.forecast(steps=1).iloc[0]\n",
        "\n",
        "        # Holt-Winters\n",
        "        hw = ExponentialSmoothing(serie, trend='add', seasonal=None).fit()\n",
        "        prev_hw = hw.forecast(steps=1).iloc[0]\n",
        "\n",
        "        resultados.append({\n",
        "            'AGRUPAMENTO': agrupamento,\n",
        "            'SES_2024': round(prev_ses, 2),\n",
        "            'ARIMA_2024': round(prev_arima, 2),\n",
        "            'SARIMA_2024': round(prev_sarima, 2),\n",
        "            'HOLT_WINTERS_2024': round(prev_hw, 2),\n",
        "        })\n",
        "\n",
        "    df_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "    df_resultados_spark = spark.createDataFrame(df_resultados)\n",
        "\n",
        "    df_resultados_spark = (\n",
        "        df_resultados_spark\n",
        "        .withColumn(\"SES_2024\", ceil(\"SES_2024\").cast(\"int\"))\n",
        "        .withColumn(\"ARIMA_2024\", ceil(\"ARIMA_2024\").cast(\"int\"))\n",
        "        .withColumn(\"SARIMA_2024\", ceil(\"SARIMA_2024\").cast(\"int\"))\n",
        "        .withColumn(\"HOLT_WINTERS_2024\", ceil(\"HOLT_WINTERS_2024\").cast(\"int\"))\n",
        "    )\n",
        "\n",
        "    display(df_resultados_spark)\n",
        "\n",
        "    df_resultados_spark.write.saveAsTable(tabela_destino)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c95b27ed-d74d-4327-83e7-f22981545fbd",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "dwWAe6kWA9-5"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "659b296e-1031-410c-9263-6dba74b3849d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "vsWxPv6tA9-5"
      },
      "outputs": [],
      "source": [
        "#PASSO 1 - importação das origens\n",
        "\n",
        "#criação das tabelas de eleitorado\n",
        "anos_eleitorado = [2012, 2014, 2016, 2018, 2020, 2022, 2024]\n",
        "cria_tabelas_eleitorado(anos_eleitorado)\n",
        "\n",
        "#criação da tabela de locais de votação\n",
        "cria_tabela_locais_de_votacao()\n",
        "\n",
        "#leitura das tabelas de origem\n",
        "(\n",
        "    tb_eleitorado_2024,\n",
        "    tb_eleitorado_2022,\n",
        "    tb_eleitorado_2020,\n",
        "    tb_eleitorado_2018,\n",
        "    tb_eleitorado_2016,\n",
        "    tb_eleitorado_2014,\n",
        "    tb_eleitorado_2012,\n",
        "    locais_de_votacao\n",
        ") = ler_tabelas_origem()\n",
        "\n",
        "# -----------------------------------\n",
        "\n",
        "\n",
        "#PASSO 2 - Preparação das bases de origem (base de cálculo e base de validação)\n",
        "\n",
        "#unifica as tabelas utilizadas para base de cáculo\n",
        "anos_eleitorado_modelo = [2022, 2020, 2018, 2016, 2014, 2012]\n",
        "df_eleitorado_unificado = unificar_eleitorado(anos_eleitorado_modelo)\n",
        "\n",
        "#adiciona bairro aos dataframes de cálculo e validação\n",
        "df_eleitorado_bairro = adicionar_bairro_eleitorado(df_eleitorado_unificado, locais_de_votacao)\n",
        "df_eleitorado_bairro_2024 = adicionar_bairro_eleitorado(tb_eleitorado_2024, locais_de_votacao)\n",
        "\n",
        "#ajuste de coluna de faixa etária\n",
        "df_eleitorado_bairro = ajustar_faixa_etaria(df_eleitorado_bairro)\n",
        "df_eleitorado_bairro_2024 = ajustar_faixa_etaria(df_eleitorado_bairro_2024)\n",
        "\n",
        "#salva tabelas trabalhadas\n",
        "salvar_tabelas_trabalhadas(df_eleitorado_bairro, df_eleitorado_bairro_2024)\n",
        "\n",
        "# -----------------------------------\n",
        "\n",
        "\n",
        "#PASSO 3 - Preparação das bases agrupadas (base de cálculo e base de validação)\n",
        "\n",
        "#leitura das tabelas trabalhadas\n",
        "df_eleitorado_bairro, df_eleitorado_bairro_2024 = ler_tabelas_trabalhadas()\n",
        "\n",
        "#separação da amostra de trabalho\n",
        "bairro = \"CENTRO\"\n",
        "df_eleitorado_bairro_amostra = filtrar_bairro(df_eleitorado_bairro, bairro)\n",
        "df_eleitorado_bairro_2024_amostra = filtrar_bairro(df_eleitorado_bairro_2024, bairro)\n",
        "\n",
        "#definição das bases agrupadas\n",
        "base_predicao = \"workspace.perfil_eleitorado.base_predicao\"\n",
        "base_validacao = \"workspace.perfil_eleitorado.base_validacao\"\n",
        "\n",
        "#agrupamento pela variável de quantidade total\n",
        "agrupar_quantidade_total(df_eleitorado_bairro_amostra, base_predicao)\n",
        "agrupar_quantidade_total(df_eleitorado_bairro_2024_amostra, base_validacao)\n",
        "\n",
        "#agrupamento pelas demais variáveis\n",
        "agrupamentos = [\n",
        "    {\"nome\": \"ESCOLARIDADE - \", \"coluna\": \"ESCOLARIDADE\"},\n",
        "    {\"nome\": \"GENERO - \", \"coluna\": \"GENERO\"},\n",
        "    {\"nome\": \"ESTADO CIVIL - \", \"coluna\": \"ESTADO_CIVIL\"},\n",
        "    {\"nome\": \"FAIXA ETARIA - \", \"coluna\": \"FAIXA_ETARIA\"},\n",
        "]\n",
        "for agrupamento in agrupamentos:\n",
        "    agrupar_e_salvar(\n",
        "        df_eleitorado_bairro_amostra,\n",
        "        agrupamento[\"nome\"],\n",
        "        agrupamento[\"coluna\"],\n",
        "        base_predicao\n",
        "    )\n",
        "    agrupar_e_salvar(\n",
        "        df_eleitorado_bairro_2024_amostra,\n",
        "        agrupamento[\"nome\"],\n",
        "        agrupamento[\"coluna\"],\n",
        "        base_validacao\n",
        "    )\n",
        "\n",
        "# -----------------------------------\n",
        "\n",
        "\n",
        "#PASSO 4 - Projeção\n",
        "\n",
        "base_final = \"workspace.perfil_eleitorado.base_projecao_final\"\n",
        "projetar_base(base_predicao, base_final)\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "2"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "Perfil de Eleitorado 20250903",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}